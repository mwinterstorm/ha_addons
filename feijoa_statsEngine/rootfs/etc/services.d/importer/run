#!/usr/bin/with-contenv bashio

set -euo pipefail

APP_DIR="/usr/local/share/feijoa"
PYTHON_IMPORTER="/opt/feijoa-venv/bin/python3 ${APP_DIR}/s3_contributions_to_sql.py"

bashio::log.level "$(bashio::config 'log_level')"

export AWS_ACCESS_KEY_ID="$(bashio::config 'aws_access_key_id')"
export AWS_SECRET_ACCESS_KEY="$(bashio::config 'aws_secret_access_key')"
export AWS_REGION="$(bashio::config 'aws_region')"

export S3_BUCKET="$(bashio::config 's3_bucket')"
export S3_PREFIX="$(bashio::config 's3_prefix')"

export CHUNK_SIZE="$(bashio::config 'chunk_size')"
export USERS_CHUNK_SIZE="$(bashio::config 'users_chunk_size')"

export DB_HOST="$(bashio::config 'mariadb_host')"
export DB_PORT="$(bashio::config 'mariadb_port')"
export DB_USER="$(bashio::config 'mariadb_user')"
export DB_PASSWORD="$(bashio::config 'mariadb_password')"
export DB_NAME="$(bashio::config 'mariadb_database')"

export TZ="$(bashio::config 'timezone')"

if [ ! -f "${APP_DIR}/s3_contributions_to_sql.py" ]; then
  bashio::log.error "Expected python importer at ${APP_DIR}/s3_contributions_to_sql.py, but it is missing."
  bashio::log.error "Ensure your importer files are present in the image."
  exit 1
fi

if bashio::config.true 'use_cron'; then
  CRON_FILE="/tmp/feijoa-crontab"
  SCHEDULE="$(bashio::config 'schedule')"
  if bashio::is_empty "${SCHEDULE}"; then
    bashio::log.error "Cron schedule is empty but use_cron is enabled. Please configure a schedule like '0 * * * *'."
    exit 1
  fi

  # Note: supercronic does not pass environment variables from this script by default.
  # We must export them to a file that supercronic can load.
  # We also redirect stderr to stdout (2>&1) to ensure Python errors are logged.
  cat <<EOF > "${CRON_FILE}"
${SCHEDULE} ${PYTHON_IMPORTER} --bucket "${S3_BUCKET}" --prefix "${S3_PREFIX}" --exec-db --chunk-size "${CHUNK_SIZE}" --users-chunk-size "${USERS_CHUNK_SIZE}" 2>&1
EOF
  bashio::log.info "Starting supercronic with schedule: ${SCHEDULE}"
  exec /usr/local/bin/supercronic -quiet "${CRON_FILE}"
fi

bashio::log.info "Starting single-run import."

# We run the python script and redirect stderr to stdout (2>&1) to ensure
# any Python tracebacks are captured in the add-on logs.
# We also capture the exit code to log a clear success or failure message.
if ${PYTHON_IMPORTER} \
  --bucket "${S3_BUCKET}" \
  --prefix "${S3_PREFIX}" \
  --exec-db \
  --chunk-size "${CHUNK_SIZE}" \
  --users-chunk-size "${USERS_CHUNK_SIZE}" 2>&1; then
  bashio::log.info "Import script finished successfully."
else
  bashio::log.error "Import script failed. See traceback above for details."
fi
